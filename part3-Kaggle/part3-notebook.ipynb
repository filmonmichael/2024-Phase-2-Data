{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9000772,"sourceType":"datasetVersion","datasetId":5421938},{"sourceId":9000851,"sourceType":"datasetVersion","datasetId":5421998}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import statments","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n\n# main imports for model fitting \nfrom tensorflow.keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D,Input,BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras import layers, models,optimizers\nfrom tensorflow.keras.regularizers import l2\n\n#model tuning imports\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom tensorflow.keras.optimizers import Adam, RMSprop\n\nfrom tensorflow.keras.models import Model\n\n#evaluation improts\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T03:32:50.765116Z","iopub.execute_input":"2024-07-28T03:32:50.765963Z","iopub.status.idle":"2024-07-28T03:32:50.939888Z","shell.execute_reply.started":"2024-07-28T03:32:50.765933Z","shell.execute_reply":"2024-07-28T03:32:50.939113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing and loading data","metadata":{}},{"cell_type":"code","source":"# This is a function i made to help read the training images in RGB format\ndef load_images_from_folder(folder, image_ids):\n    images = []\n    #loops through each image file in the given folder (train or test)\n    for img_id in image_ids:\n        img_path = os.path.join(folder, f\"image_{img_id}.png\") # concatinating\n        image = cv2.imread(img_path)\n        if image is not None:\n            # cv2 automatically uses BGR format so changed it to RGB for the model to learn better\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n            image = cv2.resize(image, (32, 32)) #ensuring image size is 32*32\n            images.append(image)\n        else:\n            print(f\"Image {img_path} could not be loaded.\")\n    return np.array(images)\n\n# Load training data\ntrain_df = pd.read_csv('/kaggle/input/complete-data-set/train.csv')\n\n# Load images and labels\ntrain_images = load_images_from_folder('/kaggle/input/complete-data-set/cifar10_images/train', train_df['id'].values)\ntrain_labels = train_df['label'].values.astype(int)  # Ensure labels are integers\n\n# Normalize images to help model learn better\ntrain_images = train_images / 255.0\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.3, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T01:42:23.239825Z","iopub.execute_input":"2024-07-28T01:42:23.240464Z","iopub.status.idle":"2024-07-28T01:45:25.497249Z","shell.execute_reply.started":"2024-07-28T01:42:23.240434Z","shell.execute_reply":"2024-07-28T01:45:25.495967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data preprocessing\n#Using split function to get test image id's from the filenames of each image as that's the format they came in\ntest_ids = [f.split('.')[0].split('_')[1] for f in os.listdir('/kaggle/input/complete-data-set/cifar10_images/test')]\ntest_images = load_images_from_folder('/kaggle/input/complete-data-set/cifar10_images/test', test_ids)\n# Normalize images to match the training data\ntest_images = test_images / 255.0\n","metadata":{"execution":{"iopub.status.busy":"2024-07-26T07:14:37.334584Z","iopub.execute_input":"2024-07-26T07:14:37.335189Z","iopub.status.idle":"2024-07-26T07:15:01.693682Z","shell.execute_reply.started":"2024-07-26T07:14:37.335147Z","shell.execute_reply":"2024-07-26T07:15:01.692148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save preprocessed data as numpy arrays so that we don't have to rerun the steps everytime \nnp.save('/kaggle/working/X_train.npy', X_train)\nnp.save('/kaggle/working/y_train.npy', y_train)\nnp.save('/kaggle/working/X_val.npy', X_val)\nnp.save('/kaggle/working/y_val.npy', y_val)\n\nnp.save('/kaggle/working/test_images.npy', test_images)\nnp.save('/kaggle/working/test_ids.npy', test_ids)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T01:45:30.378285Z","iopub.execute_input":"2024-07-28T01:45:30.379151Z","iopub.status.idle":"2024-07-28T01:45:31.485109Z","shell.execute_reply.started":"2024-07-28T01:45:30.379110Z","shell.execute_reply":"2024-07-28T01:45:31.483932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load required data everytime we restart the notebook \n\nX_train = np.load('/kaggle/working/X_train.npy')\ny_train = np.load('/kaggle/working/y_train.npy')\nX_val = np.load('/kaggle/working/X_val.npy')                  \ny_val = np.load('/kaggle/working/y_val.npy')\ntest_images = np.load('/kaggle/working/test_images.npy')\ntest_ids = np.load('/kaggle/working/test_ids.npy')","metadata":{"execution":{"iopub.status.busy":"2024-07-28T01:45:38.546343Z","iopub.execute_input":"2024-07-28T01:45:38.546700Z","iopub.status.idle":"2024-07-28T01:45:38.980602Z","shell.execute_reply.started":"2024-07-28T01:45:38.546665Z","shell.execute_reply":"2024-07-28T01:45:38.979783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the shape of our data to insure it's correct before we feed it into the model\nprint(X_train.shape, y_train.shape, X_val.shape, y_val.shape, test_images.shape, test_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T01:46:21.820528Z","iopub.execute_input":"2024-07-28T01:46:21.821609Z","iopub.status.idle":"2024-07-28T01:46:21.831438Z","shell.execute_reply.started":"2024-07-28T01:46:21.821559Z","shell.execute_reply":"2024-07-28T01:46:21.829939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualisation","metadata":{}},{"cell_type":"code","source":"#checking some of the training images to visually inspect they have been correctly loaded\nfig, ax = plt.subplots(5, 5)\nk = 0\n \nfor i in range(5):\n    for j in range(5):\n        ax[i][j].imshow(X_train[k], aspect='auto')\n        k += 1\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T02:20:08.056498Z","iopub.execute_input":"2024-07-28T02:20:08.056883Z","iopub.status.idle":"2024-07-28T02:20:10.642904Z","shell.execute_reply.started":"2024-07-28T02:20:08.056852Z","shell.execute_reply":"2024-07-28T02:20:10.641999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Fitting ","metadata":{}},{"cell_type":"code","source":"\n\n# Defining the number of classes\nK = len(set(y_train))\n\n# Calculating total number of classes for the output layer\nprint(\"Number of classes:\", K)\n\n# Building the model using the functional API a common technique\ni = Input(shape=X_train[0].shape)\n\n# Convolutional layers with Batch Normalization and Dropout\nx = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(i)\nx = BatchNormalization()(x)\nx = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\nx = Dropout(0.3)(x) \n\nx = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\nx = BatchNormalization()(x)\nx = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\nx = Dropout(0.3)(x)  \n\nx = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\nx = BatchNormalization()(x)\nx = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\nx = Dropout(0.3)(x)  \n\nx = Flatten()(x)\nx = Dropout(0.4)(x)  \n\nx = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)  # Reduced number of neurons\nx = Dropout(0.4)(x)  \n\n# Output layer\nx = Dense(K, activation='softmax')(x)\n\nmodel = Model(i, x)\n\n# Model description\nmodel.summary()\n\n# Compiling the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Early stopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=10, restore_best_weights=True)\n\n# Learning rate scheduler\ndef scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        return float(lr * tf.math.exp(-0.1))\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n\n# Data augmentation\nbatch_size = 32\ndata_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n\ntrain_generator = data_generator.flow(X_train, y_train, batch_size)\nsteps_per_epoch = X_train.shape[0] // batch_size\n\n# Training the model with data augmentation, early stopping, and learning rate scheduler\nhistory = model.fit(train_generator, validation_data=(X_val, y_val),\n                    steps_per_epoch=steps_per_epoch, epochs=100,\n                    callbacks=[early_stopping, lr_scheduler])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T01:51:27.832378Z","iopub.execute_input":"2024-07-28T01:51:27.833244Z","iopub.status.idle":"2024-07-28T02:10:08.925396Z","shell.execute_reply.started":"2024-07-28T01:51:27.833209Z","shell.execute_reply":"2024-07-28T02:10:08.924573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating model","metadata":{}},{"cell_type":"markdown","source":"# Visualization of model performance","metadata":{}},{"cell_type":"code","source":"# plotting the accuracy of our model to visually see how well it's performing\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T03:28:43.039840Z","iopub.execute_input":"2024-07-28T03:28:43.040222Z","iopub.status.idle":"2024-07-28T03:28:43.267279Z","shell.execute_reply.started":"2024-07-28T03:28:43.040194Z","shell.execute_reply":"2024-07-28T03:28:43.266457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model performance on the training set\ntrain_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n#priting training accuracy\nprint(f'Training Accuracy: {train_accuracy:.4f}')\n\n# model performance on the validation set\nval_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n#priting validation accuracy\nprint(f'Validation Accuracy: {val_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-28T03:28:52.515600Z","iopub.execute_input":"2024-07-28T03:28:52.516289Z","iopub.status.idle":"2024-07-28T03:28:57.844219Z","shell.execute_reply.started":"2024-07-28T03:28:52.516257Z","shell.execute_reply":"2024-07-28T03:28:57.843217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting the labels for the validation set since we don't have the labels for the test set \ny_pred_prob = model.predict(X_val)\ny_pred_classes = np.argmax(y_pred_prob, axis=1)\n\n# Calculating the confusion matrix\nconf_matrix = confusion_matrix(y_val, y_pred_classes)\n\n# Calculating precision, recall, F1-score, and accuracy\nprecision = precision_score(y_val, y_pred_classes, average='weighted')\nrecall = recall_score(y_val, y_pred_classes, average='weighted')\nf1 = f1_score(y_val, y_pred_classes, average='weighted')\naccuracy = accuracy_score(y_val, y_pred_classes)\n\n# Printing the metrics\nprint(f'Overall Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1-score: {f1:.4f}')\n\n# Printing a classification report as there's a handy function for this\nprint('\\nClassification Report:')\nprint(classification_report(y_val, y_pred_classes))\n\n# Plot the confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T03:45:31.033737Z","iopub.execute_input":"2024-07-28T03:45:31.034116Z","iopub.status.idle":"2024-07-28T03:45:33.317119Z","shell.execute_reply.started":"2024-07-28T03:45:31.034087Z","shell.execute_reply":"2024-07-28T03:45:33.316182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Interpreting Metrics\nThe overall accuracy represents the ratio of correctly predicted labels to the number of total labels.\nMy model correctly predicts 82.28% of the validation data.\n\n### Precision: The ratio of true positive predictions and total predicted positives.\nA precision of 82.73% means that when my model predicts a specific class it predicts correctly 82.73% of the time.\n\n### Recall: This is the ratio of true positive predictions and total actual positives.\nA recall of 82.28% shows that my model correctly identifies 82.28% of all actual instances of a class.\n\n### F1-score.\nAn F1 score where it stands at 82.01% implies that there exists good balance between precision and recall in my model.\n\n# Interpretation of the confusion matrix:\nEach row of the matrix show the observations in the actual class, while each column represents the observations in a predicted class.\nThe diagonal elements indicate the number of observations that have been correctly classified, while off-diagonal elements are misclassifications.\nThe confusion matrix provides a detailed breakdown of correct and incorrect predictions for each class, allowing us to identify specific areas where the model may struggle.\nWe can see the column for class 7 has the most misclassifications.\nClass 0 being misclassified as 5 vice versa.","metadata":{}},{"cell_type":"markdown","source":"# Submitting Predictions","metadata":{}},{"cell_type":"code","source":"# Predict the labels for the test set to be submitted\ntest_predictions = model.predict(test_images)\ntest_labels = np.argmax(test_predictions, axis=1)\n\n# Prepare the submission file\nsubmission_df = pd.DataFrame({'id': test_ids, 'label': test_labels})\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary","metadata":{}},{"cell_type":"markdown","source":"This analysis was carried out on images. Hence i have decided to use a Convolutional Neural Network (CNN) with the “relu” activation function. To make this model, I used functional API which is a very commonly used technique in deep learning.\n\nI began by defining the input shape depending on the shapes of training images. Then, I added several convolutional layers, each followed by batch normalization and dropout layers to improve regularization. I specifically used kernel regularizer with L2 penalty to avoid overfitting and stabilize the training process using batch normalization.\n\nFor my convolutional layers, I started with 32 filters and then increased them to 64 filters in the next layers. Each set of convolutional layers was followed by a max pooling layer that reduces spatial dimensions and dropout layer that further prevents overfitting. As the network got deeper, I gradually increased the dropout rate for more regularization.\n\nAfter convolutional layers, I flattened out the output and added a dense layer having 512 neurons along with dropout rate of 0.4. Output layer had number of neurons equal to classes’ number and had “softmax” activation function at final stage in order to get final classification probabilities.\n\nIn compiling my model, I utilized an optimizer called “adam”, which is well-suited for training deep neural networks and \"sparse_categorical_crossentropy\" being the loss function as the labels are integers that represent the classes. \n\nTo further reduce overfitting i utilized earlystopping. This stops the training process when the validation loss does not show an improvement. I also used a learning rate scheduler which makes the learning rate lower over time to ensure the model is not simply learning the training data too well. \nTo generalize the model i have used data augmentation techniques such as width and height shifts and horizontal flips. This helped increase the training data size. The batch size was set to 32 and data augmentation used on each batch. I set the number of epochs to be 100 to allow enough for the model to train better given all the steps i have taken to reduce overfitting. However if no improvements were seen in the validation loss the training would end earlier due to the implementation of early stopping.\n\nAn accuracy of 84.84% was achieved by the model during training.\nThe early stopping and learning rate scheduler introduced helped the model minimize overfitting. As a result, it has been able to generalize well on unseen data.\nAs we can see the precision, recall, and F1-score measures all confirm that the model gives equal consideration to different classes.\nFor example, some classes are well predicted by the model while others need improvement as seen from the confusion matrix.\nOn validation set performance was strong with an overall accuracy of 82.28%, precision of 82.73%, recall of 82.28% and F1-score of 82.01%.\n","metadata":{}},{"cell_type":"markdown","source":"# Possible Next Steps to Improve the Model:\n1. Experimenting with different hyperparameters such as learning rate, batch size, and the number of layers/neurons to find the optimal configuration. \n    - Could also use Gridsearch/ Bayesian Optimization/ Random Search to help with this.\n    \n2. Trying more aggressive data augmentation techniques like zoom, and shear transformations to make the model more robust.\n3. Adding more regularization techniques such as L1 regularization or increase the strength of L2 regularization to reduce overfitting.\n5. Utilizing pre-trained models to leverage existing knowledge and improve performance.\n\n","metadata":{}}]}